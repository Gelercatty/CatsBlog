---
title: 矩阵分析
date: 2025-12-18 15:31:23
tags: 线性代数 矩阵分析
mathjax: true
---

## 线性空间
中文/毛子/工科教材中常见的叫法。 或者叫向量空间。
### 定义
如果数集$F$ 任意两个数加减乘除仍属于$F$ ，即$F$ 对四则运算是封闭的, 则$F$ 是一个数域

对于一个$F$ 在$V$上有8条公理，则称$V$ 是 $F$ 上的线性空间
1. 加法交换
2. 加法结合
3. 定一个 $0 \in V$ , $0+V=V$
4. 对于任意的元素$V$, 存在$-v$ 使得 $v + -v = 0$ 
5. 乘法对加法的分配
6. 加法对乘法的分配
7. 数乘的结合率
8. 具有单位元 $1$

### 线性无关
设 $V$ 是域 $\mathbb{F}$ 上的线性空间，$v_1,\dots,v_k\in V$。

向量组 $\{v_1,\dots,v_k\}$ **线性无关** 当且仅当
$$
\forall\,a_1,\dots,a_k\in\mathbb{F},\quad
a_1v_1+\cdots+a_kv_k=0 \ \Rightarrow\ a_1=\cdots=a_k=0,
$$
其中 $0$ 是 $V$ 的零向量。

意味着，这组向量中的任意一个向量，都无法用其他的向量通过系数加减得到。

### 基底

**向量组** ${x_1, x_2, ..., x_n}$ 中的每个向量线性无关，并且$V$ 中的任一向均可以由${x_1, x_2, ..., x_n}$ 线性组合表出，那么这组向量就是一组基底。

通过线性组合的定义，存在任意的$x \in V$,有
$$x=\sum_{j=1}^n{a_jx_j}$$

这组系数，也就是这个向量，在这组基下面的坐标。

- 推论1：$n(<\infty)$ 维空间 $V$中任意n个线性无关的向量都是基底，任意k( <n ) 个线性无关的向量组可以通过扩充成为一组基
- 推论2: 对n维空间V中任意给定的一组基底${x_1, x_2, ..., x_n}$和任意向量x，x由这组基底唯一线性表出
- 推论3: 一个可逆矩阵可以把一组基映射到另一组基:$y=Bx$



### 维数
设$V$是$F$ 上的线性空间，则$V$ 的**基底**中线性无关的元素个数为$V$的维数，记为$dim(V)$

$dim(V) < \infty$ ，$v$ 是有限维空间

以上定义和推论可以告诉我们这些直观的感受：
- 在同一个数领$F$上，只讨论有限维线性空间的线性结构时，区别本质上是**维数**
- 任何指定基底的操作，都是为这个线性空间注入观测坐标系，让我们通过研究坐标，矩阵的方式，对空间性质进行观测研究.
- 基底本身并不改变空间本身的线性结构，只影响我们对他的表达方式。

### 过渡矩阵$B$
基底里面的推论3，表达了两个基底之间的映射。此时如果有一个向量分别在两个基底下的坐标
$$x=[x_1,x_2,...,x_n]\alpha = [y_1,y_2,...,y_n]\beta$$
$$\alpha=(a_1,a_2,...,a_n),  \beta=(b_1,b_2,...,b_n)$$
则有 $\alpha = B\beta$

过渡矩阵说明了当我们在研究任意的坐标转换时，只需要研究基底之间的[线性变换](#线性变换)即可。

## 子空间 维数定理
### 定义
设$V$是数域$F$上的线性空间，非空集合$W \subseteqq V$, 如果$W$中的向量关于$V$上的线性运算也构成线性空间，则称$W$上$V$的子空间

其中$V$和$\{0\}$是$V$的两个平凡子空间

#### 交空间

设 $U, V$ 是向量空间 $W$ 的子空间。它们的**交空间**定义为
$$
U \cap V \;=\; \{\, x \in W \mid x \in U \text{ 且 } x \in V \,\}.
$$
也就是说，$U \cap V$ 由**同时属于** $U$ 和 $V$ 的所有向量组成，并且 $U\cap V$ 仍然是 $W$ 的子空间。

x轴和y轴交于0，0就是子空间，则两个也是直和
#### 和空间
设 $U, V$ 是向量空间 $W$ 的子空间。它们的**和空间**定义为
$$
U + V \;=\; \{\, u+v \mid u \in U,\; v \in V \,\}.
$$
也就是说，$U+V$ 由从 $U$ 里取一个向量、从 $V$ 里取一个向量相加得到的所有向量组成，并且 $U+V$ 也是 $W$ 的子空间。

最直接的，就是xy平面

#### 直和空间
设 $U, V$ 是向量空间 $W$ 的子空间。若满足
$$
U \cap V = \{0\},
$$
则称 $U+V$ 是 $U$ 与 $V$ 的**直和**，记作
$$
U \oplus V.
$$

或者说，一个子空间$W$ = $W_1$+$W_1$, $W$在$W_1$ $W_2$上有唯一的分解，那么$W$是$W_1$和$W_2$的直和空间

**直和定理**：

$W=W_1+W_2$

- $W=W_1+W_2$
- $W_1 \cap W_2 = \{0\}$
- $dim(W) = dim(W_2) + dim(W_1)$

#### 代数补空间

如果$V$ = $W_1$ + $W_2$ 那么$W_1$和$W_2$互为代数补空间

### 维数定理
$$
\dim(W_1 + W_2) = \dim(W_1) + \dim(W_2) - \dim(W_1 \cap W_2).
$$


### 线性空间之间的不同
两个线性空间的不同，可以从以下方面直观感受：
#### 维数不同
$dimV ≠ dimW$时, $V$和$W$不可能`同构` 
这时，线性变换$T:V \rightarrow W$可以看作是“从n维到m维”的类型，$R^3 \rightarrow R^2$投影，或者$R^2 \rightarrow R^3$的嵌入。
#### 维数相同，但集合层面$F$存在差异，但是结构可以同构
考虑这种情况：
- $V = P_2$: 所有次数≤2的多项式
- $W = R^3$
一个的元素是多项式，一个的元素是三元组。几何不同，但是$dimV = dimW = 3$作为线性空间是同构的。

## 线性变换
### 定义
对$V$， $W$ 是数域$F$ 上的（两个不同的）线性空间，如果映射 $T: V \rightarrow W$满足
$$T(\lambda x + \mu y) = \lambda T x + \mu T y, \forall \lambda\mu \in F, xy \in V$$ 

则称$T$是 $V$ 到 $W$的一个线性映射

- 这里面$T(⋅)$是一个`函数/映射`。具体的函数值是在$W$里面的向量。
- 其中$\lambda x + \mu y$代表的是线性组合的意思。 
- 类比于线性齐次多项式$y = ax$，线性变换的输入是一个线性空间里面的向量的线性组合，输出是另一个线性空间的向量。
- 这个定义同时提示了，这个线性变换，可以分别对线性组合里面的每个量进行变换，之后在再进行线性组合
- 即，先在$V$里做线性组合后再变换，等价于，先分别变换得到$W$里面的向量，再用同样的系数再线性组合

$W$代表的线性空间相当于是`值域`, $V$相当于`定义域`。

线性变换的另一个好处，就是能提供两个`不同的线性空间`之间的联系关系。只要这两个集合带上线性空间结构（在F上的运算封闭），就能通过线性变换矩阵进行转换。

比如多项式集合到坐标向量的转换：
$$V = P_2 = {a+bx+cx^2}, W=R^3$$
$$T(a+bx+cx^2) = (a,b,c)$$

线性变换能够把不同类型的对象联系起来，但前提是这些对象所在的集合本身是线性空间。

所有从$T: V \rightarrow W$的线性变换集合，记做$L(V,W)$

$T \in L(V,W)$ 表示一个具体的线性变换。

一个矩阵在这个线性变换选定基底后得以给出。

### 核空间
固定一个线性变换$T:V \rightarrow W$
找出所有被$T$送入$W$中0的$x$的集合，这些x组成的空间就叫$N(T)$核空间（0空间）

$dimN(T)$叫零度，也就是有多少个方向会被压成0

和空间一定也是$V$的一个子空间。既然这个空间本身是由那些在线性变换过程中被压缩到0向量张成，那么这个空间的维度也就揭示了原空间被压扁的维度。
### 相空间
$R(T)$, 线性变换的秩也就是$R : dimR(T)$

相空间表达了那些输入被送到哪里。
### 亏加秩定理
在线性代数里面，矩阵的秩$R$，代表了矩阵中那些有效的部分。这里我们扩展：


根据定义自然而然的引出亏加秩定理:
设$T \in L(V,W)$, $dimV< \infin$
$$dimR(T) + dimN(T) = dim(V)$$

一个线性变换（具象化来讲，就是矩阵）由他的像空间，和被压缩到0的零空间组成。

### 线性变换的矩阵表示，及同构

#### 线性变换的矩阵表示
我们其实隐约已经注意到了，线性变换，实际上就是矩阵的的抽象表示，而矩阵，则以具体的数字，描述了一个线性变换。
我们现在来讨论线性变换的矩阵表示。

在一个线性空间中，任意一个向量，都能够由一组[基](#基底)的线性组合表出，而在同一个线性空间的线性变换，结果也是一个在这个线性空间中的向量(这里线性变换的系数使用$x$来表示便于坐标和单纯系数的区分)，
$$v = \sum_{j=1}^n{x_je_j}$$
由[线性变换的性质](#线性变换)，
$$T(v) = T(\sum_{j=1}^nx_je_j) = \sum_{j=1}^nx_jT(e_j)$$

我们想关注于线性变换对整个线性空间结构的改变，而基底是能张出这个空间的，任何其他的向量都能同构这组基线性表出，所以我们只关注每个基底在这个线性变化过程中的改变。

设$V$是F上的线性空间， $dimV=n,\space V=span\{e_1,...,e_n\},\space T\in L(V)$, 即V由这一堆$e_n$张成，并且定义一个从$V$到$V$的线性变换，

$$T(e_j) = x_{1j}e_1 + x_{2j}e_2 +...+x_{nj}e_n,\space j=1,...,n$$
$$T(e_j) = \sum_{i=1}^n{x_{ij}e_i}$$
$$T(e) = {Ae}$$
则称`矩阵`$A = (x_{ij})\in F^{n\times n}$ 是$T$在基底$\{e_1,e_2,...,e_n\}$下的矩阵表示。

只要基确定，那么这个线性变换的矩阵表示就是唯一的。因为在固定的基下，向量坐标的展开唯一。所以每个线性变换的系数也就唯一，而矩阵的每一列也都唯一，那么整个矩阵就唯一（人话，具体数学推倒可以自己试一下）

#### 线性变换的同构， 矩阵的相似
##### 变换同构
两个线性变换做的是同一件事，只是坐标系/基不同，所以写出来不同，这就是同构。
具体一点，考虑三个线性变换（注意这里是线性变换而非矩阵）
- $T:V\rightarrow V$
- $S:W\rightarrow W$
- $\Phi:V\rightarrow W$

如果满足$$\Phi(T(v)) = S(\Phi(v)), \forall v \in V$$
也就是说，任意一个向量，在两不同的空间中，执行不同的线性变换T，S，最后通过$\Phi$转换到同一个坐标下，是相同的结果，那么T和S就是同构的。

同构意味着：
- 特征值一样（拉伸倍率一样）
- 特征值的维数一样
- Jordan结构一样（细粒度结构，下面会讲）

##### 矩阵相似
当把线性变换写成矩阵后，
线性变换同构也就是矩阵相似。
因为坐标转换使用的[过渡矩阵](#过渡矩阵):
$$B = P^{-1}AP$$

这也就是矩阵相似。
也就是
- 同一个T换基，两个矩阵必定相似
- 两个矩阵相似，可以看成同一个线性变换在两种坐标下



## 线性变换的最简矩阵表示
一个线性变换，在不同基底下的矩阵表示都相似。
反之，所有相似矩阵描述的是同一个线性变换。
问题是能否在这么多的相似矩阵中选择一个线性变换最简单的矩阵表达。

我们要研究的，就是`特征值`，与`最小多项式`

### 特征值和特征向量
设$V$ 是$F$上上的线性空间，存在一个在$V$上的线性变换，如果存在$\lambda \in F$和非零向量的$\xi$满足
$$T\xi = \lambda \xi$$

- `特征值`： $\lambda$
- `特征向量`：$\xi$

注意这里面的定义，并不是一个矩阵，而是一个线性变换。

取$V$的一组基$e_1, e_2, ..., e_i$
用这组基去观测这个线性变换：
$$T(e_1, e_2, ..., e_n) = (e_1, e_2, ... ,e_n)A$$

则这个向量在这组基上的表达：
$$\xi = (e_1, e_2,...,e_n)\alpha$$

带回则有：
$$A \alpha = \lambda \alpha$$

线性变换的特征值和特征向量是线性变换本身固有的性质，与基底无关。线性变换作用后，

特征向量对应方向在$T$的作用下保持不变，即$T(v) = \lambda v$。对应的特征值$\lambda$给出沿该方向的缩放倍数。

求解特征值，可以通过计算
$$
det(A-\lambda I) = 0
$$
对应的特征向量是解
$$
(A-\lambda I)x = 0
$$
的非0解。
### 几何重数

特征子空间:
- A对应于特征值$\lambda$的特征子空间： $E_\lambda (A) = {a \in F^n: A\alpha = \lambda \alpha}$
- T对应于特征值$\lambda$的特征子空间: $E_\lambda (T) = {\xi \in V: A\xi = \lambda \xi}$

这些特征子空间的维度就是几何重数。

$$gm(\lambda) = dim\space ker(A-\lambda I)$$

ker是取一个线性变换的核（0）空间。

即，一个特征值所代表的特征向量张成的子空间的维数

计算时，
1. 算$A-\lambda I$
2. 解其次方程$(A - \lambda I)$x = 0，解空间的数量
3. 零空间的维数就是几何重数 

### 代数重数
$\lambda$ 作为特征多项式的重根数。

假如有一个特征多项式：
    $$p_A(\lambda) = (\lambda -1 )^2(\lambda - 3)$$
    则$\lambda = 1$的代数重数为2， $\lambda = 3$的代数重数是1
    记为：$am(\lambda)$

所有特征值的代数重数之和等于矩阵的维数n

### 几何重数和代数重数的关系
对于任意的方阵$A$ 每个特征值$\lambda$ 都满足：
$$
1 <= gm(\lambda) <= am(\lambda)
$$

### 上三角矩阵
主对角线下面的元素全是0。
$$

A= \begin{pmatrix}
    1 & 2 & 3\\
    0 & 4 & 5\\
    0 & 0 & 6\end{pmatrix}    
$$
- 行列式等于主对角线元素的乘积
- 上三角矩阵的特征值就是主对角线上的元素
- 解线性方程时 $Ax = b$可以用回代的方式。从最后一行开始往上依次回带。

#### 分块上三角矩阵
上三角矩阵的对角线元素都是一阶的，并且都是特征值。

分块上三角矩阵的对角元素允许二阶的存在


$$
R=
\begin{pmatrix}
a & b & * & *\\
-b & a & * & *\\
0 & 0 & \lambda_3 & *\\
0 & 0 & 0 & \lambda_4
\end{pmatrix}
$$

其中左上角的二阶矩阵
$$
\begin{pmatrix}
a & b\\
-b & a
\end{pmatrix}
$$
在实数域内做线性代数运算，但是有些方向上的行为天然会产生复特征值。分块上三角矩阵就是为了用实数表达出这些复特征的信息。

例如，一个旋转矩阵$\begin{pmatrix}
    0 & 1\\
    -1 & 0
\end{pmatrix}$ 他的特征值很容易求得: $\lambda ^2 = -1$

特征值就是$\plusmn1$

如果我不希望我的矩阵中变成上三角矩阵的时候，元素出现1。那么我就可以用分块三角阵代替他。这里面这个特殊的旋转矩阵本身就是符合二阶子块构造形式的。可以直接拿来使用。

二阶子块的特征方程永远是
$$
(\lambda - a)^2 + b^2 = 0
$$
$$
\lambda = a \plusmn bi
$$
### Shur引理0 

任意的$A \in C^{n*n}$都相似于上三角矩阵$R$，$R$的主对角元素是A的全部特征值。注意，这个是复数域。

该结论可以同构数学归纳法证明。

任意的$A \in R^{n*n}$都存在[分块上三角矩阵](#分块上三角矩阵)$R^{n * n}$，$R$的主对角线上的子块是一阶子块或二阶子块，一阶子块是A的所有实特征值，每个二阶子块可以求出A的一堆共轭复特征值。全部二阶子块的特征值是A的所有复特征值。

### 特征多项式 （Hamilton-Cayley定理）
为了表达"矩阵在哪些$\lambda$下会变得不可逆", 那么最直接的方法就是让他的行列式等于0，矩阵变得不可逆。这件事可以用一个多项式完整的表达出来。

对于$A \in C^{n\times n}$, 其特征多项式即为
$$
    f(\lambda) = det(\lambda I - A)
$$
这是一个关于$\lambda$ 的n次多项式
$$
f(\lambda) = \lambda^n + c_{n-1}\lambda^{n-1}+...+c_1\lambda + c_0
$$
矩阵的特征多项式有一些性质：
- 首项系数为1，首项次数为n。

求特征值的时候，就让$f(\lambda) = 0$

如果把这个特征多项式作用到矩阵上，那么

$$
f(A) = O^*
$$

$O^*$ 是零矩阵。

上面这个系数来自特征多项式，结果等于0的式子是一种特殊的`零化多项式`。`零化多项式`本身不要求系数完全来自于特征多项式，只要关于A，结果是送到0，那么这个式子就是零化多项式。可以证明零化多项式是无穷多的，因为只要存在一个零化多项式，乘上任意的一个系数或者多项式，结果肯定还是0.

特征多项式带入A后的多项式，只是其中一个零化多项式，而HC定理的内容就是，特征多项式一定是零化多项式。并且这个多项式直接和$det(\lambda I - A )$绑定，携带特征值，`代数重数`的信息

这个性质在求一个矩阵的高次幂的时候十分有用：
$$
f(A) = A^n + c_{n-1}A^{n-1}+...+c_0I = 0
$$
则有递推公式：
$$
A^n = -(c_{n-1}A^{n-1} + ... + c_0I)
$$


对于一个 2x2 的矩阵，
$$
A = \begin{pmatrix}
    a & b \\
    c & d
\end{pmatrix}
$$

计算他的特征多项式：
$$
f(\lambda) = det(\lambda I - A)= det\begin{pmatrix}
    \lambda - a & -b \\
            - c & \lambda - d
\end{pmatrix}  = (\lambda - a)(\lambda - b ) - bc = \lambda^2 - (a+b)\lambda + (ad - bc)
$$
注意到：
- $trA = a + d$
- $detA = ad-bc$ 

直接写出特征多项式：
$$
f(\lambda) = \lambda^2 - (trA)\lambda + det(A)
$$

根据CH定理，直接把$\lambda$换成矩阵，则有
$
A^2 = (trA)A - det(A) I 
$

如果我要算$A^k$，把等式两边同时乘上$A^{k-2}$: $A^k = tr(A)A^{k-1}-det(A)A^{k-2}$

这个就是由CH导出的二阶矩阵求幂公式。

再从矩阵推广到线性变换上，设$T \in L(V), f(\lambda)$是$T$的特征多项式，则有$f(T) = O^*$


### 矩阵A属于不同特征值的特征向量线性无关
这个好理解，每个特征值都代表了线性空间里面一个方向被矩阵改变的长度。不同的长度变化一定对应的是不同的特征向量（方向），不同的方向在线性空间里面肯定是线性无关的。

### 矩阵和线性变化的零化多项式和最小多项式
由HC定理可以知道，一个矩阵或者线性变换，总是存在零化多项式的。而特征多项式就是其中之一。我们关心的是次数最低的零化多项式的性质。

`最小多项式`是指，零化多项式中次数最低，且首项系数为1的多项式。记为$m_A(\lambda)$

$m_A(\lambda)$唯一存在，且可整除A的任意零化多项式。即任意的零化多项式$P(\lambda)$，都可以表达为$m_A(\lambda)q(\lambda)$。

特征多项式$f(\lambda)$不一定就是最小多项式$m_A(\lambda)$，他们的关系是
$$
m_A(\lambda)\space |\space f_A(\lambda)
$$

很显然特征多项式和最小多项式具有相同的根（不记重根），因为最小多项式可以通过与q组合，整除任意零化多项式，而特征多项式也是零化多项式。

至此，我们可以分析线性变换的最简矩阵。


### 矩阵对角化

#### 对角阵

##### 对角阵（Diagonal Matrix）性质整理

设对角阵  
$$
D=\mathrm{diag}(d_1,d_2,\dots,d_n)=
\begin{pmatrix}
d_1&0&\cdots&0\\
0&d_2&\cdots&0\\
\vdots&\vdots&\ddots&\vdots\\
0&0&\cdots&d_n
\end{pmatrix}.
$$

---

##### 1) 加法、数乘、乘法

- 加法/数乘仍为对角阵：  
$$
\mathrm{diag}(d_i)+\mathrm{diag}(e_i)=\mathrm{diag}(d_i+e_i),\qquad
c\,\mathrm{diag}(d_i)=\mathrm{diag}(cd_i).
$$

- 乘法逐元素相乘，且对角阵之间可交换：  
$$
\mathrm{diag}(d_i)\,\mathrm{diag}(e_i)=\mathrm{diag}(d_ie_i),\qquad
DE=ED.
$$

---

##### 2) 幂、多项式与矩阵函数（逐对角元素）

- 幂：  
$$
D^k=\mathrm{diag}(d_1^k,\dots,d_n^k).
$$

- 多项式：若 $p(\lambda)$ 为多项式，则  
$$
p(D)=\mathrm{diag}(p(d_1),\dots,p(d_n)).
$$

- 常见矩阵函数（若定义良好）：  
$$
e^D=\mathrm{diag}(e^{d_1},\dots,e^{d_n}),\qquad
\sin D=\mathrm{diag}(\sin d_1,\dots,\sin d_n).
$$

---

##### 3) 行列式、迹、秩

- 行列式：  
$$
\det(D)=\prod_{i=1}^n d_i.
$$

- 迹：  
$$
\mathrm{tr}(D)=\sum_{i=1}^n d_i.
$$

- 秩：  
$$
\mathrm{rank}(D)=\#\{i:\ d_i\neq 0\}.
$$

---

##### 4) 可逆与逆矩阵

- 可逆条件：  
$$
D \text{ 可逆} \iff d_i\neq 0\ \forall i.
$$

- 逆矩阵：  
$$
D^{-1}=\mathrm{diag}\!\left(\frac{1}{d_1},\dots,\frac{1}{d_n}\right).
$$

---

##### 5) 特征值、特征向量、谱半径

- 特征值就是对角元（按重数）：  
$$
\sigma(D)=\{d_1,\dots,d_n\}.
$$

- 标准基向量 $e_i$ 是特征向量：$De_i=d_ie_i$。

- 谱半径：  
$$
\rho(D)=\max_i |d_i|.
$$

---

##### 6) 正定/半正定判别（实对角）

$$
D\succeq 0 \iff d_i\ge 0\ \forall i,\qquad
D\succ 0 \iff d_i>0\ \forall i.
$$

---

##### 7) 常用范数

- 谱范数（诱导 $2$-范数）：  
$$
\|D\|_2=\max_i |d_i|.
$$

- Frobenius 范数：  
$$
\|D\|_F=\sqrt{\sum_{i=1}^n |d_i|^2}.
$$

- 条件数（$2$-范数，且可逆）：  
$$
\kappa_2(D)=\frac{\max_i |d_i|}{\min_i |d_i|}.
$$

---

##### 8 与对角化的关系（补充）


若矩阵 $A$ 可对角化：$A=VDV^{-1}$，则幂/矩阵函数可先在 $D$ 上逐元素计算，再共轭回去。

### 线性变换的对角阵分析


线性变换的最简矩阵是对角阵，那么为什么？这里讨论为什么线性变换的最简矩阵是对角阵，他在哪一组基底下的矩阵是对角阵。

对于给定的线性变换$T$，设A是它在某组基底下的矩阵，那么$T$所有的矩阵都与A相似，且所有与A相似的矩阵都是T的矩阵表示。因此，如果要分析T的最简矩阵，之需要分析所有与A相似的矩阵中的最简单的矩阵，以及这个观测用的基底即可。


如果$A$相似于一个对角阵，则$A$是可对角化矩阵，或单纯型矩阵。如果线性变换$T$的矩阵$A$相似于一个对角阵，或$T$在某组基底下的矩阵是对角阵，那么称$T$可对角化

问题是，如何判断一个给定的矩阵是否可对角化？

矩阵 $A \in C^{n\times n}$可对角化的充分必要条件是所有特征值的[几何重数](#几何重数)和[代数重数]()相等
$$
am(\lambda)= gm(\lambda)
$$

代数重数描述了一个特征值理论上应该出现几次，几何重数描述了这个特征值实际上给了几个独立方向

对角化就是需要把空间分解到这些方向的[直和](#直和空间)，并且方向数量等于n。

所以当且仅当每个特征值都“不欠方向”，就能够对角化。

推论：如果n阶方针有n个互异的特征值，则A可对角化。

进一步推广到$F$，则有：$A \in F^{n\times n}$可对角化的充分必要条件是$A$的最小多项式$m_A(\lambda)$可以分解成不同的一次因子的积，也就是无重根
